# GenAI Project - Assistente Conversacional com Flask e Kubernetes

Este projeto Ã© um assistente conversacional baseado em Flask e integrado com Google Gemini AI. Ele possui suporte a buscas inteligentes via Tavily Search e estÃ¡ preparado para deploy em Docker e Kubernetes.

## ğŸ“Œ Estrutura do Projeto

```
genai-project/
â”‚   â”œâ”€â”€ templates/              # Templates HTML do front-end
â”‚   â”œâ”€â”€ static/                 # Arquivos estÃ¡ticos (CSS, JS, imagens)
â”‚   â”œâ”€â”€ agents/                 # LÃ³gica dos agentes conversacionais
â”‚   â”‚   â”œâ”€â”€ agents.py           # ConfiguraÃ§Ã£o do chatbot e integraÃ§Ã£o com Gemini AI
â”‚   â”œâ”€â”€ routes/                 # DefiniÃ§Ã£o das rotas da API
â”‚   â”‚   â”œâ”€â”€ routes.py           # ConfiguraÃ§Ã£o das rotas para interaÃ§Ã£o com o chatbot
â”‚   â”œâ”€â”€ logs/                    # Arquivos de logs
â”‚   â”œâ”€â”€ app.py                  # InicializaÃ§Ã£o do app Flask e configuraÃ§Ã£o geral
â”‚   â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â”‚   â”œâ”€â”€ Dockerfile              # ConfiguraÃ§Ã£o do container Docker
â”‚   â”œâ”€â”€ k8s/                    # ConfiguraÃ§Ãµes para Kubernetes
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”œâ”€â”€ aws-architecture.png    # Arquitetura do projeto na AWS
â”‚   â”œâ”€â”€ .env.example            # Exemplo do arquivo de variÃ¡veis de ambiente
â”‚   â””â”€â”€ README.md               # DocumentaÃ§Ã£o do projeto
```

---

## ğŸ” ExplicaÃ§Ã£o dos Principais Arquivos

### `agents.py`
Este arquivo contÃ©m a implementaÃ§Ã£o do agente conversacional. Ele integra a API do Google Gemini AI para fornecer respostas inteligentes e usa o Tavily Search para buscas na web. TambÃ©m define a lÃ³gica do fluxo de conversa e a moderaÃ§Ã£o de conteÃºdo sensÃ­vel.

### `routes.py`
Define as rotas da API do Flask. ContÃ©m:
- `/`: Rota para exibir a interface do chatbot.
- `/api/ask`: Rota para receber perguntas e retornar respostas usando o agente conversacional.

### `app.py`
Arquivo principal para inicializar o Flask. Ele:
- Configura as blueprints das rotas.
- Carrega variÃ¡veis de ambiente.
- Configura CORS.
- Implementa verificaÃ§Ãµes de saÃºde (`/health`).
- Garante seguranÃ§a com HSTS quando usando HTTPS.

---

## ğŸš€ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o do Projeto

### 1ï¸âƒ£ PrÃ©-requisitos
- **Python 3.10+**
- **Docker & Docker Compose**
- **Kubernetes & Kubectl (para deploy em K8s)**
- **Google Gemini API Key**
- **Tavily API Key**

### 2ï¸âƒ£ Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto e adicione as seguintes variÃ¡veis:

```
GEMINI_API_KEY=your_google_gemini_api_key
TAVILY_API_KEY=your_tavily_api_key
SECRET_KEY=your_secret_key
CORS_ORIGINS=*
```

### 3ï¸âƒ£ Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Rodar Localmente

```bash
python app.py
```

Acesse a interface no navegador: [http://127.0.0.1:5000](http://127.0.0.1:5000)

### 5ï¸âƒ£ Executar com Docker

**Construir a imagem:**
```bash
docker build -t flask-app .
```

**Rodar o container:**
```bash
docker run -d -p 5000:5000 --name flask-container flask-app
```

**Logs o container:**
```bash
docker logs -f flask-container
```


### 6ï¸âƒ£ Deploy no Kubernetes

**Aplicar os arquivos de configuraÃ§Ã£o:**
```bash
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/ingress.yaml  # Opcional
```

**Verificar os pods:**
```bash
kubectl get pods
```

### 7ï¸âƒ£ Testar API

```bash
curl -X POST http://localhost:5000/api/ask -H "Content-Type: application/json" -d '{"question": "O que Ã© Machine Learning?"}'
```

SaÃ­da esperada:
```json
{
  "answer": "Machine Learning Ã© um campo da inteligÃªncia artificial que ..."
}
```

---

## ğŸ“œ LicenÃ§a
Este projeto Ã© open-source e segue a Apache License.

---

ğŸ‘¨â€ğŸ’» **Desenvolvido por Ernane Domingues** ğŸš€

